{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "torch_floating_point_type = torch.float32\n",
    "torch_complex_float_type = torch.complex64\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "df = 300\n",
    "propogation_dists = [df, df]\n",
    "wl = 532e-6\n",
    "pixel_size = 18e-3\n",
    "k = torch.pi * 2 / wl"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def meshgrid(size_x: float, n_x: int = 512, size_y: float = None, n_y: int = None):\n",
    "    if not size_y: size_y = size_x\n",
    "    if not n_y: n_y = n_x\n",
    "\n",
    "    x_range = torch.linspace(-size_x / 2, size_x / 2, int(n_x), dtype=torch_floating_point_type, device=device)\n",
    "    y_range = torch.linspace(-size_y / 2, size_y / 2, int(n_y), dtype=torch_floating_point_type, device=device)\n",
    "\n",
    "    x, y = torch.meshgrid(x_range, y_range, indexing='xy')\n",
    "    return x, y\n",
    "\n",
    "def rrmse(x1: torch.Tensor, x2: torch.Tensor):\n",
    "    res = (x1 - x2) ** 2\n",
    "    res = torch.sqrt(torch.sum(res) / x1.numel()) / torch.mean(torch.abs(x2))\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "LOAD DATASET"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from core.config import torch_floating_point_type, torch_complex_float_type\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "transforms = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.uint8, scale=True),\n",
    "    v2.Resize(size=(56, 56), antialias=False),\n",
    "    v2.ToDtype(torch_floating_point_type, scale=True),\n",
    "    # v2.RandomInvert(p=1.0),\n",
    "    v2.Pad(padding_mode='constant',fill=0, padding=228),\n",
    "    # v2.GaussianNoise(mean=0.1,sigma=0.2),\n",
    "    v2.ToDtype(torch_complex_float_type, scale=True),\n",
    "    v2.Lambda(lambda x: x/torch.sqrt((abs(x)**2).sum())),\n",
    "])\n",
    "train_dataset: Dataset = MNIST(root ='../../data/datasets/', download = True, train=True, transform=transforms)\n",
    "test_dataset: Dataset = MNIST(root ='../../data/datasets/', download = True, train=False, transform=transforms)\n",
    "\n",
    "sample_idx = torch.randint(len(train_dataset), size=(1,)).item()\n",
    "image, label = train_dataset[sample_idx]\n",
    "plt.imshow(abs(image[0]), cmap = 'gray')\n",
    "print('Label:', label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from schemas import PropagationParameters\n",
    "\n",
    "# from services.geometry import meshgrid\n",
    "\n",
    "img_shape = train_dataset[0][0][0].shape\n",
    "n_x = img_shape[0]\n",
    "app_size = n_x * pixel_size\n",
    "\n",
    "x,y = meshgrid(size_x=app_size, n_x=n_x)\n",
    "\n",
    "propagation_params = PropagationParameters(im_size=(n_x,n_x),\n",
    "                                           wave_number=k,\n",
    "                                           aperture_size=app_size,\n",
    "                                           dists=propogation_dists)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "GENERATE REQUIRED REGIONS (MASKS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_rings = 1\n",
    "area_r = app_size /16\n",
    "\n",
    "num_classes = len(train_dataset.classes)\n",
    "num_phi = math.ceil((num_classes - 1) / num_rings) # one class in center\n",
    "dphi = 2 * math.pi / num_phi\n",
    "dr = 2 * num_phi * area_r / math.pi\n",
    "\n",
    "req_center_x = [0.]\n",
    "req_center_y = [0.]\n",
    "\n",
    "cur_r = dr/2\n",
    "cur_start_phi = 0\n",
    "for _ in range(num_rings):\n",
    "    cur_phi = cur_start_phi\n",
    "    while len(req_center_x) < num_classes and cur_phi < cur_start_phi + 2 * math.pi:\n",
    "        req_center_x.append(cur_r * math.cos(cur_phi))\n",
    "        req_center_y.append(cur_r * math.sin(cur_phi))\n",
    "        cur_phi += dphi\n",
    "\n",
    "    cur_r += dr\n",
    "    cur_start_phi += dphi / 2\n",
    "\n",
    "# find correspond inds\n",
    "cell_dist = x[0,1] - x[0,0]\n",
    "\n",
    "req_center_x = x.new_tensor(req_center_x)\n",
    "req_center_y = x.new_tensor(req_center_y)\n",
    "req_center_x_ind = torch.ceil((req_center_x - x.min())/cell_dist)\n",
    "req_center_y_ind = torch.ceil((req_center_y - y.min())/cell_dist)\n",
    "\n",
    "req_masks = x.new_zeros((num_classes, n_x, n_x))\n",
    "for i in range(num_classes):\n",
    "    req_masks[i] = (x - req_center_x[i]) ** 2 + (y - req_center_y[i]) ** 2 <= area_r ** 2\n",
    "\n",
    "plt.imshow(req_masks.sum(dim=0).cpu().numpy() > 0, cmap = 'gray')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "DEFINE SPLINEs (LAYERS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "degree = 3\n",
    "\n",
    "n_points = n_x\n",
    "nknots = [20, 80, 160, 320]\n",
    "\n",
    "c_s = []\n",
    "knots_x_s = []\n",
    "knots_y_s = []\n",
    "\n",
    "n_layeres_max = len(nknots)\n",
    "for i in range(n_layeres_max):\n",
    "    knots_x_s.append(torch.linspace(-app_size / 2, app_size / 2, nknots[i]).to(device=x.device, dtype=x.dtype))\n",
    "    knots_y_s.append(torch.linspace(-app_size / 2, app_size / 2, nknots[i]).to(device=x.device, dtype=x.dtype))\n",
    "    n_c = (nknots[i] + degree - 1) ** 2\n",
    "    # c_s.append(math.pi * 2 * torch.rand(n_c).to(device=x.device, dtype=x.dtype))\n",
    "    c_s.append(x.new_zeros(n_c))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pre-train first lvl to focus on outer surface"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from flux_visualizer import show_planar_flux\n",
    "from sinc_propagator import propagation_sinc_prepare, propagation_sinc\n",
    "# from loss_funcs import rrmse\n",
    "from models import LayeredDOE\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "input = x**2 + y**2 <= area_r **2\n",
    "input = (input/torch.sqrt((abs(input)**2).sum()))\n",
    "input = input.to(dtype=torch_complex_float_type)\n",
    "\n",
    "focur_area_r = dr + area_r\n",
    "req_distr = x**2 + y**2 <= focur_area_r **2\n",
    "req_distr = req_distr / req_distr.sum()\n",
    "\n",
    "loss_fn = rrmse\n",
    "lr_start = 1e-1\n",
    "num_iters = int(2e3)\n",
    "\n",
    "c_s[0].requires_grad = True\n",
    "doe = LayeredDOE(x=x, y=y, degree = degree, c_s=c_s[:1], knots_x_s=knots_x_s[:1], knots_y_s=knots_y_s[:1])\n",
    "optimizer = torch.optim.Adam(doe.parameters(), lr=lr_start, betas=(0.9, 0.99999), eps=1e-08, weight_decay=0)\n",
    "lr_end = lr_start/100\n",
    "gamma = math.pow(lr_end / lr_start, 1 / num_iters)\n",
    "scheduler = ExponentialLR(optimizer, gamma=gamma)\n",
    "\n",
    "\n",
    "prop_params = [propagation_sinc_prepare(field_shape=propagation_params.im_size,\n",
    "                                        wavenumber=propagation_params.wave_number,\n",
    "                                        side_length=propagation_params.aperture_size,\n",
    "                                        propagation_dist=f) for f in propagation_params.dists]\n",
    "\n",
    "with tqdm(total=num_iters) as pbar:\n",
    "    for i in range(num_iters):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        result = propagation_sinc(u1=input, propagator_params=prop_params[0])\n",
    "        result = doe(result)\n",
    "        result = propagation_sinc(u1=result, propagator_params=prop_params[1])\n",
    "        result = abs(result) ** 2\n",
    "\n",
    "        loss = loss_fn(result, req_distr)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        if i % 5 == 4:\n",
    "            pbar.set_description(f'Iteration {i + 1:5d}.  Loss: {loss:.3f}')\n",
    "        pbar.update(1)\n",
    "\n",
    "c_s[0].requires_grad = False\n",
    "\n",
    "show_planar_flux(image=[abs(input),  result, doe.get_phase_surface()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save/Load prepared data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # SAVE RESULTS TO FILE\n",
    "# f_name = 'tmp_data.pt'\n",
    "# d = {'c_s': c_s,\n",
    "#      'knots_x_s': knots_x_s,\n",
    "#      'knots_y_s': knots_y_s,\n",
    "#      'degree': degree,\n",
    "#      'nknots': nknots,}\n",
    "#\n",
    "# torch.save(d, f_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# LOAD RESULTS FROM FILE\n",
    "f_name = 'tmp_data.pt'\n",
    "d = torch.load(f_name)\n",
    "\n",
    "nknots = d['nknots']\n",
    "c_s = d['c_s']\n",
    "knots_x_s = d['knots_x_s']\n",
    "knots_y_s = d['knots_y_s']\n",
    "degree = d['degree']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "SUPPORT FUNCTIONS"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from models import LayeredDOE\n",
    "\n",
    "def get_layered_doe(num_layeres):\n",
    "    return LayeredDOE(x=x, y=y, degree = degree, c_s=c_s[:num_layeres], knots_x_s=knots_x_s[:num_layeres], knots_y_s=knots_y_s[:num_layeres])\n",
    "\n",
    "def get_data_loaders(batch_size):\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, test_loader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "DNN TRAINING"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import math\n",
    "from models import SimpleLayeredDNN\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import time\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "stages = [ # (num_layers, batch_size, lr_start, num_epochs)\n",
    "        # (1,16,1e-1,1),\n",
    "        (2,32,1e-2,20),\n",
    "        (3,64,1e-2,20),\n",
    "        (4,128,1e-3,20),\n",
    "        ]\n",
    "\n",
    "num_iters_to_log = 5\n",
    "\n",
    "for c in c_s:\n",
    "    c.requires_grad = True\n",
    "\n",
    "print(f'Start training.')\n",
    "start_time = time.time()\n",
    "for (num_layers, batch_size, lr_start, num_epochs) in stages:\n",
    "    train_loader,_ = get_data_loaders(batch_size)\n",
    "    num_iters_in_epoch = len(train_loader)\n",
    "\n",
    "\n",
    "\n",
    "    layered_dnn = SimpleLayeredDNN(propagation_params=propagation_params,\n",
    "                                       target_regions=req_masks,\n",
    "                                       layered_doe=get_layered_doe(num_layers))\n",
    "    layered_dnn.to(device=device)\n",
    "    plt.imshow(layered_dnn.doe.get_phase_surface().cpu().detach().numpy(), cmap = 'gray')\n",
    "    plt.show()\n",
    "\n",
    "    optimizer = torch.optim.Adam(layered_dnn.parameters(), lr=lr_start, betas=(0.9, 0.99999), eps=1e-08, weight_decay=0)\n",
    "\n",
    "    lr_end = lr_start/10\n",
    "    gamma = math.pow(lr_end / lr_start, 1 / num_epochs)\n",
    "    scheduler = ExponentialLR(optimizer, gamma=gamma)\n",
    "    print(f'New stage begin.Batch size: {batch_size}; {num_layers} spline layers; {lr_start} starting step; {num_epochs} epochs.')\n",
    "\n",
    "    with tqdm(total=num_epochs) as sbar:\n",
    "        sbar.set_description(f'Stage: {num_layers} layers, batch size={batch_size}, start LR= {lr_start}.')\n",
    "        for epoch in range(num_epochs):\n",
    "            running_loss = 0.0\n",
    "            with tqdm(total=num_iters_in_epoch) as pbar:\n",
    "                for i, data in enumerate(train_loader, 0):\n",
    "                    inputs, labels = data[0].to(device=device), data[1].to(device=device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward + backward + optimize\n",
    "                    outputs = layered_dnn(inputs)\n",
    "\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    # print statistics\n",
    "                    running_loss += loss.item()\n",
    "                    if i % num_iters_to_log == num_iters_to_log-1:    # print every 100 mini-batches\n",
    "                        # num_iters = i * batch_size + inputs.size(dim=0)\n",
    "                        pbar.set_description(f'Epoch #{epoch + 1}, iteration {i + 1:5d}.  Loss: {running_loss / i+1:.3f}')\n",
    "                    pbar.update(1)\n",
    "            scheduler.step()\n",
    "            sbar.update(1)\n",
    "\n",
    "print(f'Finished Training. {(time.time() - start_time):.4} s.')\n",
    "for c in c_s:\n",
    "    c.requires_grad = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from models import SimpleLayeredDNN\n",
    "# prepare to count predictions for each class\n",
    "classes = train_dataset.classes\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "layered_dnn = SimpleLayeredDNN(propagation_params=propagation_params,\n",
    "                                   target_regions=req_masks,\n",
    "                                   layered_doe=get_layered_doe(2))\n",
    "layered_dnn.to(device=x.device)\n",
    "\n",
    "_,test_loader = get_data_loaders(128)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data[0].to(device=x.device), data[1].to(device=x.device)\n",
    "        outputs = layered_dnn(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')\n",
    "\n",
    "show_planar_flux(image=[abs(images[0,0]),  abs(layered_dnn.trace_field(images[0,0]))**2, layered_dnn.doe.get_phase_surface()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}